---
title: The Ends of Reading
defaults: toc-defaults
---

## Introduction

I began the research I'm sharing with you today while writing about neither the sociology of reading nor the crises of the humanities, but from small discoveries in two big datasets. When I first found these datasets, I assumed that they must already be widely known. (And perhaps they are to some of the people in this room.) But, in general, that turned out not to be the case. I want to bring these surveys to the attention of literary studies in particular, and scholars in general, for reasons that I hope will be both obvious and persuasive.

Let's start with three numbers:

**SLIDE**

I'll explain each of these momentarily. But they make two important points obvious: As points 1 and 2 suggest, over the past thirty years, the odds of people in the US reading literature or anything else for pleasure have gone down by almost half. And as the third point makes clear, that relative decline is being subtracted from leisure reading rates that weren't very high to begin with.

## Census numbers

The US Census Bureau has been collecting statistics about reading for pleasure since 1982 in two surveys from which I calculated these numbers: the Survey of Public Participation in the Arts and the American Time Use Survey. I compiled historical data about pleasure reading from both surveys in one place for the first time, pulling some figures out of old government reports, and others from data newly published in June, and performed new analyses.

My most basic point is that it is bad that the humanities generally and literary studies particularly are broadly unaware of these figures. Literary studies has been vigorously arguing about *how* to read over the past few decades: surface vs. depth, close vs. distant, critical vs. postcritical, etc. The significance of those distinctions all follow from an unstated presumption about the continuity of reading. Literary studies should concern itself more than it presently does with *whether* and *to what extent* people read. If one of the core activities of literary studies is to cultivate and improve reading, our ability to do that well depends upon an understanding of the present state of reading.

I have some ideas about why literary studies has ignored or repressed this information, but we can talk about that during the Q&A.

## The Current Population Survey (CPS)

**SLIDE**

In order to talk about the reading surveys, we first need to talk about the Current Population Survey.

CPS measures labor force participation rates. You are almost certainly familiar with its most famous statistic, which is the unemployment rate.

The CPS "is a monthly sample survey of 60,000 eligible households."^[@LaborForceStatistics2020] It uses a probability sample to estimate state and national population characteristics, weighting for factors including race, gender, and education.^[@Sampling2022] Eligible survey respondents are 16 or older and neither in the military nor institutionalized.

While the main purpose of CPS is to gather data about the labor force, it also fields a number of supplemental surveys. The first survey we'll be looking at comes from one such supplement, and the second selects its respondents from the CPS pool of households.[@30DayNotice20222021; @AmericanTimeUse2024]

## The Survey of Public Participation in the Arts

**SLIDE**

The research division of the National Endowment for the Arts (NEA) fields and analyzes the SPPA.[@marquisNationalEndowmentsArts2013; @iyengarAligningArtsResearch2022] Its work has been used as ammunition in both the reading wars and canon wars.^[For a compelling review of the reading wars, see @johnsScienceReadingInformation2023, 323-375. On the NEA, the National Endowment for the Humanities, and the canon wars, see @gatesLooseCanonsNotes1992, 87-105.]

To the extent that scholars know about the SPPA, it is almost certainly by way of the NEA's reports. The best known of these is the 2004 *Reading at Risk*, which showed broad declines in reading.[@ReadingRiskSurvey2004a] More recent reports on the SPPA have drawn less controversy. Unfortunately, less controversy has also meant less attention. That has been a mistake.

### Methodology

**SLIDE**

The NEA's research division studies the impact of public participation in the arts on learning, public health, and economic activity, among other things.[@Research2023] That means they have two distinct incentives for their surveys. First, they want to keep the questions as consistent as possible from one survey to the next in order to measure change over time. Second, they also need to update the survey methodology to accommodate changes that impact *how* people participate in the arts. Obvious examples in the case of reading since 1982 would include reading on the internet, e-readers, and audiobooks.

The SPPA asks respondents the following questions about reading:

**SLIDE**

They only count voluntary reading, not what is done for work or school. Religious texts "count as books" for the first question. "Reading" is not restricted to the form of the codex; this includes e-readers and audiobooks.^[The 2008 SPPA was the first to explicitly include online reading of these literary forms in its instructions.]

The SPPA makes a distinction between books and what it calls "literature." Respondents are asked if they read any books. But they have never been asked if they read literature. Literature is the designation that the NEA uses to refer to the set of all respondents who reported reading any novels, short stories, poetry, and/or plays in the preceding year.

### Data

With those details in mind, let's look at the national SPPA data for reading any book and reading literature:

**SLIDE**

The y-axis shows the percentage of the US population who read either type of writing over the previous twelve months, and the x-axis shows the survey year. The dashed line denotes half of the population.

The big drop in book reading from 1985 to 1992 can probably be explained by a changed question. In 1982 and 1985, they asked if respondents read "any books or magazines." After 1985, it was limited to "any books." However, the "literature" definition has been consistent since 1982.

Reading literature once (or more) per year had passed from a majoritarian to a minoritarian activity by 2012. And, for the first time in 2022, the same is true for reading any book in the preceding year.

We can also decompose "literature" into its constituent parts:

**SLIDE**

Literature readers and prose fiction readers are almost equal. Readers of poetry and plays are much smaller groups, and few people in those groups solely read poetry or plays to the exclusion of prose fiction.

You can further subset the SPPA data by various Census categories like race, gender, education, and income. Here's a quick summary of what that shows: Educational attainment is the strongest predictor of reading. If you were guessing which group of Americans were most likely to have read any book in the preceding year, you should guess college-educated white women, which is no surprise given that they are also book publishers' primary market.[@mcgrathBooksRaceCommercial2022; @sinykinBigFictionHow2023; @daneWhiteLiteraryTaste2023]

### Odds ratios

While these graphs give us a sense of directionality, it is hard to reason about the magnitude of these changes from percentages.

**SLIDE**

Odds ratios can help us reason about how big these changes are by comparing them to a *reference year*.^[Previous studies have used odds ratios to evaluate changing participation rates in the SPPA, and I have adapted their methods to the questions about reading. I use the same method as in the following paper, but applied to a different set of questions: @dimaggioArtsParticipationCultural2004, 176-177]

**SLIDE**

The odds of reading any book in 2022 are 61.4% of what they were in 1992. Put another way, the odds of reading any book in 2022 are 38.6% less than they were in 1992. This is the kind of calculation that I cited in the opening slide.

**SLIDE**

You can read this graph of odds ratios (and the ones that follow) by applying the following sentence structure to each value: "The odds that a respondent read literature within the past year were 44% lower in 2022 than they were in 1992." The story is clearly one of decline---every value is negative---but not in a uniform way.

What remains unclear from these figures is whether the rate of decline is increasing, and what the nadir of reading might be. The SPPA has been taken at uneven intervals, and drops have been jagged. Still, the odds of reading in the preceding year are clearly lower than they used to be.

## The American Time Use Survey

**SLIDE**

The American Time Use Survey, to which we now turn, gives us more detailed information about the extent of reading not over the previous year, but over the previous day.

The ATUS has been conducted annually since 2003, except in 2020 due to the pandemic.[@ImpactCoronavirusCOVID192022] It began in the wake of a bill that called for a survey to calculate the monetary value of unpaid work like homemaking.[@InformationRespondents2015]

The ATUS's reading statistics differ from those of the SPPA in two key ways, one advantageous and the other disadvantageous for my purposes. The advantageous difference is that the ATUS is more precise than the SPPA, recording the number of minutes respondents read yesterday. Remember that the SPPA asked respondents whether they had read in the preceding year.

The disadvantageous difference is that, unlike the SPPA, the ATUS makes no distinction between literary forms.^[However, unlike the SPPA, the ATUS excludes the reading of religious texts from its general category of reading for personal interest. This has been true for every ATUS since 2007. @Differences200320222023, 18] That said, the reading measured by the ATUS includes nonprofessional literary reading as a subset of all reading it reports.

### Methodology

**SLIDE**

Like the SPPA, the ATUS is also conducted on a representative subset of the Current Population Survey. One person from each CPS household is randomly selected to respond to the ATUS, and they report how they used their time over one predetermined day.[@AmericanTimeUse2018] Census workers then aggregate specific time use reported by respondents in their diaries to more general categories. So, if you say, "I read *The New Yorker* for 30 minutes," and that's not part of your job, the Census will classify that as "reading for personal interest" for 30 minutes.

**SLIDE**

Here are the activities that the ATUS counts as reading for personal interest.[@ATUSActivityCoding]

This list may seem to exclude what N. Katherine Hayles has described as "hyper reading," which is the rapid non-linear reading we do on the internet.[@haylesHowWeThink2012, 61-68; @haylesPostprintBooksBecoming2021, 133-170] Some hyper reading might fall under the ATUS category of "Computer use for leisure (exc. Games)," and some activities that involve reading---like messaging with friends---would be considered socializing. But skimming news sites *is* reading for personal interest.

### Reading for personal interest yesterday

**SLIDE**

We see something similar to the SPPA in the ATUS data: a decline in the proportion of the population reading for personal interest. However, we begin from a lower point: The percentage of people reading yesterday has fallen from about 28% at its peak in 2004 to about 16% in 2023.

**SLIDE**

As we did with the SPPA, let us also look at the odds ratios relative to the earliest comparable value, which is 2003. Unlike the SPPA, not every point in the ATUS data shows a decline. The odds were slightly higher through 2006 relative to 2003 before they begin to decline.

### Reading vs. other leisure

Given the persistent decline after 2010, you're no doubt wondering about the role played by reading's most oft-cited enemies: television, games, and, above all else, the internet, especially on smartphones. The ATUS collects data on the role played by these during leisure time.

**SLIDE**

This graph shows odds ratios for participation in leisure activities viewed as competition to reading.^[Note that the names I give in the charts are abbreviated forms of the full ATUS activity names. The full names for the activities referenced in the columns, from left to right, are: Socializing, Relaxing, and Leisure (12), Television and movies (not religious) (120303), Reading for personal interest (120312), Playing games (120307), and Computer use for leisure (exc. Games) (120308). @ATUSActivityCoding]

Computer use for leisure (which excludes games) and games are the big winners. To be clear, this survey does not allow us to say that individual respondents are "trading" reading time for computing or gaming time. But that is certainly possible. It is also worth noting that, over the period of the survey, respondents report having as much or more leisure time than they had in 2003.

### Reading by education

**SLIDE**

While all of the ATUS values presented thus far are weighted to represent the US population, they can be decomposed into demographic groups.

When we break out the ATUS data by educational attainment---which is the best predictor of reading---we see three noteworthy patterns.^[I'm grateful to the Bureau of Labor Statistics for sharing these estimates with me, which the BLS does not publicize.]

**SLIDE**

First, even as reading for personal interest declines, education continues to strongly predict reading. The higher your education, the higher the chance that you read yesterday. Second, despite the fact that education is associated with more reading, the odds of participation have declined for all groups. Third, since the ATUS began in 2003, *none* of these educational groups have been more likely than not to read for personal interest on any given day. Not reading is the default.

Odds ratios reveal something important about this story. Although education continues to predict reading, their changing odds ratios are more similar than their baseline reading rates are.

But educational attainment still matters a great deal: Those with less than a high school education had an 81% lower chance of reading in 2022 than they had in 2004.^[Although 2023 ATUS data is out, the breakouts by education are not yet available.]

## "Reading class" vs. "reading culture"

**SLIDE**

The sociologist of reading Wendy Griswold draws a distinction between what she terms a reading class and a reading culture. All societies with writing have reading classes, but few societies have ever had what Griswold calls reading cultures. The reading class is defined by its professional and nonprofessional reading, as well as its elite socioeconomic status. A reading culture, by contrast, "is a society where reading is expected, valued, and common."[@griswoldRegionalismReadingClass2008, 37] In Griswold's terms, these declining odds suggest the erosion of the US reading *culture*, which Griswold argues peaked from the late-nineteenth to the mid-twentieth century.

If there is any truth in Griswold's distinction, disciplines like literary studies, which that formed during the US's reading culture, may need to reconceptualize themselves as a reading class without a reading culture.^[On the formation of professional literary studies in the nineteenth century, see, e.g., @baldickSocialMissionEnglish1983; @vanderbiltAmericanLiteratureAcademy1986; @shumwayCreatingAmericanCivilization1994; @graffProfessingLiteratureInstitutional2007; @renkerOriginsAmericanLiterature2007; @viswanathanMasksConquestLiterary2015; @guilloryProfessingCriticismEssays2022]

**SLIDE**

Griswold has argued that,

> "professional members of the reading class are evangelists, fighting at the front line of culture to convert people to reading. Examples include teachers, professors, writers, editors, publishers, journalists, and...librarians."[@griswoldEvangelistsCultureOne2015, 97]

Yet, in my experience, there is little discussion within literary studies as to whether the field recruits people to the "reading culture," or preaches to the converted of the "reading class." This is not discussed in part because, without knowledge of these statistics, it might be hard to see the difference.

## Conclusion

I think that these numbers are profoundly difficult for professional readers to internalize. Our colleagues, friends, and family are unusually likely to be among the 16% of the population who read for personal interest yesterday.

**SLIDE**

What, if anything, is to be done? I will not suggest that literary studies could or should set itself the task of making reading more popular. In the first place, that's almost certainly a losing battle. Moreover, it's a battle that few people in literature departments would want to fight on those terms.

I have no cure, but I do have one suggestion: We know that educational attainment continues to be the best predictor of reading even as reading declines. What we do not know is whether majoring in a field that emphasizes reading is associated with more reading for pleasure than what would be expected based on graduates' educational attainment alone. As Griswold suggested, reading class professionals work to "convert" new members to the reading class. If that idea seems at all objectionable, consider the opposite proposition: What professor of literature would hope that her students, as a result of taking her courses, would read *less*?

We should research the differential impact that reading intensive majors have on reading for pleasure. We may assume that it is obvious that students of literature would do more reading for pleasure than students who do not study literature. But this is presumptuous. A null hypothesis would be that literary studies has *no impact* on reading for pleasure beyond what is explained by educational attainment. If literary studies knew its impact on reading, we might be able to evade what John Guillory has termed the overestimation of aim.[@guilloryProfessingCriticismEssays2022, 5-9] If we read to encourage and sustain others in their reading, we should want to know if we are succeeding.

Thank you.

## Works cited
